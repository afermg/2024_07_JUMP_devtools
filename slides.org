#+title: Road to JUMP Hackathon II
#+OPTIONS: ^:nil H:2 num:t toc:nil
#+DATE: 2024/07/18
#+Author: Alán F. Muñoz
#+LaTeX_CLASS: beamer
#+BEAMER_THEME: metropolis
#+BEAMER_FRAME_LEVEL: 3
#+LATEX_HEADER: \usepackage{ragged2e}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \newenvironment{JUSTIFYRIGHT}{\begin{FlushRight}}{\end{FlushRight}}
#+PROPERTY: header-args:bash :eval no :exports code 
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)

* Introduction: The challenges of accessing JUMP data
** The problem
- Loads of data and metadata.
- Limited access methods, most of which are documented in notebooks across repositories.
** The problem
#+ATTR_LATEX: :width 0.5\textwidth
[[./imgs/data_metadata.jpg]]

** Before we start
:PROPERTIES:
:BEAMER_opt: shrink=2
:END:

We will split into two section later.

*** WSL/MacOS
#+begin_example shell
python -m venv .venv
source .venv/bin/activate
pip install jump_portrait 
#+end_example

*** Nix
#+begin_example shell
mkdir demo
cd demo
nix flake init -t \
github:broadinstitute/monorepo#portrait
#+end_example

*** Test installation
#+begin_example shell
python -c "import jump_portrait"
#+end_example

** What we will learn 
- A new alternative for reproducible isolated environments
- Some commands that facilitate working on remote servers
- How to access JUMP data within Python

** Available data 
- Images for ~140k perturbations
- Metadata 
- Morphological profiles and their corrected versions
- Non-written knowledge (e.g., which JCP IDS are controls in CRISPR dataset)

** The basic needs of biologists are covered
JUMP_RR (Round-Robin) Provides simple interfaces to pre-processed data:
- Perturbation-to-perturbation match (broad.io/crispr)
- Statistically significant features (broad.io/crispr_feature)
- Image exploration (broad.io/crispr_gallery)

For *<crispr>*, *<orf>* and (gallery-only)  *<compounds>*.

** How did we use to access each data/metadata
- Images: AWS S3
- Metadata: Github repository
- Profiles: AWS S3, but before this P2P 
** Notebooks served as examples
- External data sources use "standard ids" (i.e., NCBI), but many internal ones use Broad or JUMP ids
- How do we link metadata to images/profiles?
** So instead of notebooks, I build modules/libraries to make my life more pleasant
#+ATTR_LATEX: :width 0.6\textwidth
[[./imgs/notebooks_vs_modules.jpg]]

* Today's focus: Developers and Data Scientists
** Broad_babel
Main goal: Concentrate the *essential knowledge* necessary to process JUMP perturbations.
*** Essential use-cases:
- Is this JUMP ID the same as this Entrez (NCBI) ID?
- Is X a treatment or control? If the latter, which type? (yes, there are types of positive controls)
*** Additional use-cases:
- Can I get a mapper from JUMP IDS to gene symbols or InChiKeys?
- Can I export the entire table for CRISPR, ORF and Compounds mapping perturbations to control type?
  
** JUMP_portrait
Main goal: Fetch JUMP images.
*** Essential use-cases:
- What is the [Source, Batch, Plate, Well] of my perturbation with standard name X?
- Give me the available images for [Source, Batch, Plate, Well] X.
- Give me the control images for [Source, Batch, Plate] X.

*** Additional use-cases:
- Download images and controls straight to disk

** Choose your own adventure
You can choose what to do
- Follow the main demo 
- Test the limits of jump_portrait and/or broad_babel and see if they breaks

** The breaking game
#+ATTR_LATEX: :width 0.6\textwidth
[[./imgs/bernie_help.jpg]]
** The breaking game
- Input gene names must be present in JUMP (you can check broad.io/babel)
- Inputs must respect documentation and typing

- Likely bug locations:
 - Threaded components
 - Metadata with missing images
 - Edge cases when 

- Useful things to look out for:
  - Portrait: Lazy+Anonymous S3 access via Polars 
  - Babel: Pooch to download datasets only once and keep them in disk
    
** Some ideas of things to pay attention to
- These are some edge cases
  - Brightfield fetching available but barely supported, but works for some images.
    Is there a way to reliably identify bright field channels?
Should we?
  - How do we deal with invalid entries ("null", instead of "negcon" or "trt")?

- There is still data with low accessibility. 
  -For instance, someone needed to get an =Images.csv=. For reasons (?).

- Should we aim to make everything fully transparent and accessible? Or only the sections that we consider "public-ready".
  
** Walkthrough 
- Load the corrected CRISPR profiles
- Select the features that are also present on the ORF dataset
- Calculate the most anticorrelated profiles
- Pick a feature at random (seed=42), sort it and get five JCP IDs that range from min to max.
- Find the gene name
- Fetch images for this gene in both CRISPR and ORF
- find the other available names for these genes
  
** Open call for suggestions
- What is the best way to clean test artifacts?
- Threading is a pain. Are there alternatives?
 - joblib
 - Pathos
 - Multiprocessing
** One final remark
[[./imgs/is_it_worth_the_time.png]]


** Resources
- Slides: github.com/afermg/2024_07_JUMP_devtools
- Previous slides: github.com/afermg/2024_04_hackathon_brainstorm

* org-beamer-mode :noexport:
Ensure org-beamer-mode upon save
# local variables:
# eval: (org-beamer-mode)
# end:
